{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some Issue\n"
     ]
    }
   ],
   "source": [
    "years=[]\n",
    "baseurl='https://www.iplt20.com/stats'\n",
    "resp=urllib.request.urlopen(baseurl)\n",
    "urlsoup=BeautifulSoup(resp.read().decode(),'html.parser')\n",
    "for ul in urlsoup.findAll('ul'):\n",
    "    #print(' '.join(ul['class']))\n",
    "    #'''\n",
    "    try:\n",
    "        if ' '.join(ul['class'])=='sub-menu__list inline-list wrapper':\n",
    "            for li in ul.findAll('li'):\n",
    "                years.append(li.a['href'].split('/')[-1])\n",
    "    except:\n",
    "        print('some Issue')\n",
    "    #'''\n",
    "#years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base='https://www.iplt20.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some Issue\n",
      "Data Read Problem\n",
      "2018\n",
      "some Issue\n",
      "2017\n",
      "some Issue\n",
      "2016\n",
      "some Issue\n",
      "Data Read Problem\n",
      "2015\n",
      "some Issue\n",
      "2014\n",
      "some Issue\n",
      "2013\n",
      "some Issue\n",
      "2012\n",
      "some Issue\n",
      "Data Read Problem\n",
      "Data Read Problem\n",
      "2011\n",
      "some Issue\n",
      "Data Read Problem\n",
      "Data Read Problem\n",
      "2010\n",
      "some Issue\n",
      "Data Read Problem\n",
      "Data Read Problem\n",
      "2009\n",
      "some Issue\n",
      "Data Read Problem\n",
      "Data Read Problem\n",
      "2008\n"
     ]
    }
   ],
   "source": [
    "for year in years[1:-1]:\n",
    "    os.mkdir(year)\n",
    "    os.chdir(year)\n",
    "    links=[]\n",
    "    baseurl='https://www.iplt20.com/stats/'+year\n",
    "    resp=urllib.request.urlopen(baseurl)\n",
    "    urlsoup=BeautifulSoup(resp.read().decode(),'html.parser')\n",
    "    for ul in urlsoup.findAll('ul'):\n",
    "        #print(' '.join(ul['class']))\n",
    "        try:\n",
    "            if ' '.join(ul['class'])=='side-menu-child-list':\n",
    "                for li in ul.findAll('li'):\n",
    "                    links.append(li.a['href'])\n",
    "        except:\n",
    "            print('some Issue')\n",
    "    #links\n",
    "    #Extracting Left Panel Pages Table Info\n",
    "    for link in links:\n",
    "        try:\n",
    "            fullurl=base+link\n",
    "            #print(fullurl)\n",
    "            resp=urllib.request.urlopen(fullurl)\n",
    "            soup=BeautifulSoup(resp.read().decode(),'html.parser')\n",
    "            table=soup.table\n",
    "            #********************************\n",
    "            colnames=[]\n",
    "            for th in table.tr.findAll('th'):\n",
    "                colnames.append(th.get_text())\n",
    "            #colnames\n",
    "            #********************************\n",
    "            fullData=[]\n",
    "            for tr in table.findAll('tr')[1:]:\n",
    "                li=[]\n",
    "                for td in tr.findAll('td'):\n",
    "                    li.append(td.get_text().strip())\n",
    "                fullData.append(li)\n",
    "            #********************************\n",
    "            for row in fullData:\n",
    "                li=row[1].split()\n",
    "                l1=row[-1].split()\n",
    "                row[1]=' '.join(li)\n",
    "                row[-1]=' '.join(l1)\n",
    "            #********************************\n",
    "            df=pd.DataFrame(fullData,columns=colnames)\n",
    "            #print(df)\n",
    "            #********************************\n",
    "            filename=link.split('/')[-1]+'.csv'\n",
    "            df.to_csv(filename)\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            print('Data Read Problem')\n",
    "    os.chdir('../')\n",
    "    print(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
